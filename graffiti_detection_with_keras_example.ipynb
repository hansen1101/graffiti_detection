{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use keras model to generate graffiti detections\n",
    "This example demonstrates how to use an **exported keras checkpoint** to generate detections for a set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import data_sequence, classification_auxiliary\n",
    "import generateAnnotationFromModelsPredictions, eval_model\n",
    "from utils import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from an exported checkpoint file that is placed inside the model_dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models/keras_models/Lfm_SeparatedParams_drop_0.5/'\n",
    "weight_ckpt = 'combined_loss_alpha=2.50__weights_final__epoch=140__val_loss=21.02.hdf5'\n",
    "model = eval_model.generate_model(model_dir,os.path.join(model_dir,weight_ckpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to pass **keras_preprocessing_mode=True** parameter to the **Prediction_Data_Sequence** call when using keras models.\n",
    "In addition the data sequence requires image_size, grid_sizes \n",
    "The path_to_test_images contains the images. It is recommended that this directory should contain images only.\n",
    "The Prediction_Data_Sequence produces batches of numpy image arrays and file paths where the predictions can be stored.\n",
    "The **min_scale** and **max_scale** parameters should math the values in the model's pipeline.yaml (located in the model_dir).\n",
    "To ensure that the default anchor boxes are assigend properly **gride_sizes** should also fit the models feature pyramid shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test_images = 'data/images/detection_test'\n",
    "data_limit_of_n_images = 10\n",
    "image_size = model.input_shape[1:]\n",
    "grid_sizes = []\n",
    "for output_tensor in model.outputs:\n",
    "    grid_sizes.append(output_tensor.shape[1].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = data_sequence.Prediction_Data_Sequence(\n",
    "    path_to_test_images,\n",
    "    keras_preprocessing_mode=True,\n",
    "    max_data_size=data_limit_of_n_images,\n",
    "    image_size=image_size,\n",
    "    grid_sizes=grid_sizes,\n",
    "    batch_size=4,\n",
    "    min_scale=0.1,\n",
    "    max_scale=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use detection graph to run inference for each batch. The final detections are generated from the predictions according to the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_overlap_between_distinct_detections = 0.4\n",
    "only_consider_objects_with_higher_confidence_than = 0.2\n",
    "detect_at_most_n_distinct_objects = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(len(data_generator)):\n",
    "    x_batch,y_batch = data_generator[h]\n",
    "    batch_predictions = eval_model.generate_keras_prediction_batch(x_batch,model,data_generator)\n",
    "    for i in range(batch_predictions.shape[0]):\n",
    "        predictions = batch_predictions[i]\n",
    "        positives,_ = eval_model.detect(\n",
    "            predictions,\n",
    "            iou_overlap_threshold=maximum_overlap_between_distinct_detections,\n",
    "            confidence_threshold=only_consider_objects_with_higher_confidence_than,\n",
    "            max_number_of_detections=detect_at_most_n_distinct_objects,\n",
    "        )\n",
    "        pred_image_np = classification_auxiliary.invert_tf_preprocessor(x_batch[i])\n",
    "        eval_model.plot_to_img(pred_image_np,positives,predictions,'red',12,True)\n",
    "        eval_model.plot_to_img(pred_image_np,positives,predictions,'white',6,True)\n",
    "        plt.imshow(pred_image_np)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
