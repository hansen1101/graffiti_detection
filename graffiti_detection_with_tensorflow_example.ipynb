{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tensorflow model to generate graffiti detections\n",
    "This example demonstrates how to use a **frozen tensorflow model** to generate detections for a set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import data_sequence, classification_auxiliary\n",
    "import generateAnnotationFromModelsPredictions, eval_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the detection graph from an exported checkpoint file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/tensorflow_models/ssd_inception_v2_training_2/ckpt-64000/frozen_inference_graph.pb'\n",
    "detection_graph = generateAnnotationFromModelsPredictions.load_tf_graph(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to pass **keras_preprocessing_mode=False** parameter to the **Prediction_Data_Sequence** call when using tensorflow graphs.\n",
    "The path_to_test_images contains the images. It is recommended that this directory should contain images only.\n",
    "The Prediction_Data_Sequence produces batches of numpy image arrays and file paths where the predictions can be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test_images = 'data/images/detection_test'\n",
    "image_size = 460\n",
    "data_limit_of_n_images = 10\n",
    "batch_size = 4\n",
    "keras_preprocessing_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = data_sequence.Prediction_Data_Sequence(\n",
    "    path_to_test_images,\n",
    "    keras_preprocessing_mode=keras_preprocessing_mode,\n",
    "    max_data_size=data_limit_of_n_images,\n",
    "    image_size=image_size,\n",
    "    grid_sizes=[0,0],\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use detection graph to run inference for each batch. The final detections are generated from the predictions according to the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_overlap_between_distinct_detections = 0.4\n",
    "only_consider_objects_with_higher_confidence_than = 0.3\n",
    "detect_at_most_n_distinct_objects = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(len(data_generator)):\n",
    "    x_batch,y_batch = data_generator[h]\n",
    "    batch_predictions = eval_model.generate_tf_prediction_batch(x_batch,detection_graph)\n",
    "    for i in range(batch_predictions.shape[0]):\n",
    "        predictions = batch_predictions[i]\n",
    "        positives,_ = eval_model.detect(\n",
    "            predictions,\n",
    "            iou_overlap_threshold=maximum_overlap_between_distinct_detections,\n",
    "            confidence_threshold=only_consider_objects_with_higher_confidence_than,\n",
    "            max_number_of_detections=detect_at_most_n_distinct_objects,\n",
    "        )\n",
    "        \n",
    "        pred_image_np = x_batch[i]\n",
    "        eval_model.plot_to_img(pred_image_np,positives,predictions,'red',12,True)\n",
    "        eval_model.plot_to_img(pred_image_np,positives,predictions,'white',6,True)\n",
    "        plt.imshow(pred_image_np)\n",
    "        plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
